# [ Интернет-соединение ]
# connection_timeout -- таймаут соединения в мс
user_agent=ebooksearchtool
connection_timeout=5000
read_timeout=7000

# [ Соединение с analyzer'ом ]
# analyzer_enabled -- "true" или "false"
analyzer_enabled=false
analyzer_port=9999


# [ Прокси ]
# proxy_enabled -- "true" или "false"
# proxy_type -- "http" или "socks"
proxy_enabled=false
proxy_type=http
proxy_host=192.168.0.2
proxy_port=3128


# [ Краулер ]
# max_links_count -- пока посещённых ссылок меньше этого числа, bloom filter
#     (вероятностная структура данных) промахивается не слишком часто
# max_links_from_page -- столько ссылок со страницы выбираются случайным
#     образом для дальнейшего рассмотрения
# max_queue_size -- максимальный размер очереди ссылок
# threads_count -- количество потоков
# thread_timeout_for_link -- время в мс, через которое основной поток
#     спрашивает у потоков-краулеров, с какой ссылкой каждый из них работает
# thread_finish_time -- время в мс, которое даётся потоку-краулеру на
#     завершение, если основной поток обнаружил, что с последнего опроса не
#     изменилась ссылка, над которой этот поток-краулер работает. Спустя это
#     время повисший поток перезапускается
# waiting_for_access_timeout -- максимальное время в мс, которое ждём, чтобы
#     обратиться к хосту (у некоторых хостов существуют ограничения на время
#     следующего доступа в robots.txt). Если нужно ждать больше, чем это число,
#     то забываем про ссылку
#
# 0 значит бесконечность (там, где это имеет смысл)
max_links_count=3000000
max_links_from_page=10
max_queue_size=300
threads_count=10
thread_timeout_for_link=10000
thread_finish_time=5000
waiting_for_access_timeout=5000
# large_amount_of_books -- если с хоста найдено как минимум столько книжек,
#     он навсегда признаётся большим источником
# max_links_from_host -- максимальное количество ссылок, которое может быть
#     загружено с хоста (до очередного очищения статистики)
# max_links_from_large_source -- максимальное количество ссылок, которое может
#     быть загружено с большого источника (до очередного очищения статистики)
# host_stats_cleanup_period -- период времени в мс, через который очищается
#     статистика о том, сколько ссылок откуда было скачано (это сделано, чтобы
#     не занимать много памяти устаревающей информацией)
large_amount_of_books=10
max_links_from_host=40
max_links_from_large_source=60
host_stats_cleanup_period=60000


# [ Логи ]
# debug -- ждать ввода с клавиатуры: при введённой пустой строке вывести
#     на экран и в файл информацию о каждом потоке и статистику, при
#     непустой -- завершить приложение
# debug_file -- файл, в который эту статистику выводить
#
# имена файлов можно оставить пустыми, чтобы отключить вывод в файл
debug=true
debug_file=dump.txt
found_books_file=found.xml
log_file=log.txt
log_to_screen=true

log_downloaded_robots_txt=false
log_crawled_pages=true
log_found_books=false
log_errors=true
log_misc=true
