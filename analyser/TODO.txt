Первоочередные задачи:
1)Сделать обработчик для всех данных в строке для текущей модели(базовые готовы, для всех остальных данных модели)
2)Создать алгоритм для обработки нескольких сущностей на странице, их сравнения и запросов к серверу для сравнения и затем - компановка единого файла

Общии задачи:
1)Разработать эффективный алгоритм для каждой части входных данных
2)Эффективное взаимодествие с сервером(минимизация количества запросов и их наполнения)
3)Разработать механизм формирования запросов к базе данных и алгоритм, на нем основанный(1 часть сделана)

Мелкие проблемы:
1)Изменение в простейшем алгоритме(имя автора - одно слово)
2)Timeout для подключения к БД
3)Сделать обработку списка источников для демона
4)Задание приоретеов источников при поиске для обновления данных(Amazone и т.д.)
5)Продумать случаи, когда ' не сепаратор
6)Проверить, почему не работает Munsey.
7)Сделать работу Munsey отдельно от Crawler.
