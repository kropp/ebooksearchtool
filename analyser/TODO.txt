Первоочередные задачи:
1)Сделать обработчик для всех данных в строке(базовые готовы, для всех остальных данных модели)
2)Полностью протестировать мультипоточность при обработке информации от Crawler'а

Общии задачи:
1)Разработать эффективный алгоритм для каждой части входных данных
2)Эффективное взаимодествие с сервером(минимизация количества запросов и их наполнения)
3)Разработать механизм формирования запросов к базе данных и алгоритм, на нем основанный

Мелкие проблемы:
1)Хранить ли список возможных форматов или запрашивать у сервера
2)Изменение в простейшем алгоритме(имя автора - одно слово)
3)Сделать таймаут на подключение к серверу
4)Часовой пояс для логгера -?